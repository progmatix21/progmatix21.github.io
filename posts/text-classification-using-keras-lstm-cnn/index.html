<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Text Classification Using Keras LSTM, CNN and embeddings - Progmatix 21</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Progmatix 21" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Progmatix 21</div>
					<div class="logo__tagline">My learnings: byte by byte</div>
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Text Classification Using Keras LSTM, CNN and embeddings</h1>
			<p class="post__lead">A no-fuss pipeline for binary or multiclass text classification</p>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" class="meta__icon icon icon-calendar" width="18" height="16" 
	 viewBox="0 0 458 458" style="enable-background:new 0 0 458 458;" xml:space="preserve">
<g>
	<path d="M111.938,135.598c11.046,0,20-8.954,20-20V21.597c0-11.046-8.954-20-20-20s-20,8.954-20,20v94.001
		C91.938,126.644,100.892,135.598,111.938,135.598z"/>
	<path d="M346.063,135.598c11.046,0,20-8.954,20-20V21.597c0-11.046-8.954-20-20-20s-20,8.954-20,20v94.001
		C326.063,126.644,335.017,135.598,346.063,135.598z"/>
	<path d="M443,82.403h-46.938c0,12.42,0,20.918,0,33.195c0,27.614-22.386,50-50,50c-27.614,0-50-22.386-50-50
		c0-12.281,0-20.771,0-33.195H161.938c0,12.42,0,20.918,0,33.195c0,27.614-22.386,50-50,50c-27.614,0-50-22.386-50-50
		c0-12.281,0-20.771,0-33.195H15c-8.284,0-15,6.716-15,15v89.641h458V97.403C458,89.119,451.284,82.403,443,82.403z"/>
	<path d="M0,441.403c0,8.284,6.716,15,15,15h428c8.284,0,15-6.716,15-15V227.044H0V441.403z M244.191,313.046
		c0-6.036,3.59-11.504,9.127-13.907c7.49-3.249,16.316-9.028,21.176-13.393c2.782-2.499,6.38-3.88,10.121-3.88h19.254
		c4.395,0,7.957,3.563,7.957,7.958v80.903h11.445c8.275,0,14.984,6.708,14.984,14.984c0,8.275-6.708,14.984-14.984,14.984h-59.934
		c-8.275,0-14.984-6.708-14.984-14.984c0-8.275,6.708-14.984,14.984-14.984h14.567V317.66c-2.163,2.886-6.797,6.077-12.243,8.754
		c-4.618,2.27-10.076,2.008-14.445-0.711c-4.369-2.718-7.025-7.501-7.025-12.647V313.046z M123.295,390.677
		c2.691-29.175,18.127-37.168,47.125-52.83c4.622-2.493,12.811-7.06,15.92-11.134c3.842-5.044,1.97-18.001-14.359-18.001
		c-5.549,0-11.094,1.106-17.704,5.967c-6.262,4.605-14.984,3.637-20.067-2.244l-0.594-0.688c-3.026-3.501-4.246-8.216-3.31-12.747
		s3.925-8.371,8.09-10.387c22.329-10.811,56.654-13.101,73.853,0.952c7.977,6.523,11.966,15.332,11.966,26.43
		c0,32.434-40.129,38.997-54.315,54.731h41.622c8.275,0,14.984,6.708,14.984,14.984c0,8.275-6.708,14.984-14.984,14.984h-79.1
		c-2.577,0-5.036-1.095-6.772-3C123.914,395.789,123.059,393.243,123.295,390.677z"/>
</g>
</svg>
<time class="meta__text" datetime="2024-02-09T17:27:29&#43;05:30">February 09, 2024</time></div>
<div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/deep-learning/" rel="category">deep learning</a>
	</span>
</div><div class="meta__item-categories meta__item">
	<span class="meta__text">
		<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>969 words/5 min read
	</span>
</div>
</div>
		</header>
		
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
	    <details>
	        <summary>Click to toggle</summary>
		        <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#import-libraries">Import libraries</a></li>
    <li><a href="#get-your-favourite-embeddings">Get your favourite embeddings</a></li>
    <li><a href="#create-a-vectorizer-layer">Create a vectorizer layer</a></li>
    <li><a href="#create-the-embedding-layer">Create the embedding layer</a></li>
    <li><a href="#create-the-model">Create the model</a></li>
    <li><a href="#model-training">Model training</a></li>
    <li><a href="#classification-report">Classification report</a></li>
    <li><a href="#takeaway">Takeaway</a></li>
  </ul>
</nav>
		    </details>
	</div>
</div>
<div class="content post__content clearfix">
			
<style>
#myBtn {
  display: none;
  position: fixed;
  bottom: 20px;
  right: 30px;
  z-index: 99;
  font-size: 36px;
  font-weight: bold;
  border: none;
  outline: none;
  background-color: #444;
  color: white;
  cursor: pointer;
  padding: 15px;
  border-radius: 50%;
}

#myBtn:hover {
  background-color: #008080;
}
</style>

<button onclick="topFunction()" id="myBtn" title="Go to top">&#9650;</button>


<script>

let mybutton = document.getElementById("myBtn");


window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 1000 || document.documentElement.scrollTop > 1000) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}


function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}
</script>



<h2 id="introduction">Introduction</h2>
<p>Traditionally, neural network algorithms are associated with image classification, but there are some dedicated to text classification as well.  LSTM or Long Short Term Memory networks can be used for text classification tasks.  We have also used CNN, an image classification oriented algorithm in our text classification.</p>
<p>In this blog post, we look at a 24-class symptom-to-disease classification problem <a href="https://www.kaggle.com/datasets/niyarrbarman/symptom2disease">kaggle dataset</a>.  This is a rather challenging problem because of the large number of labels and relatively few cases per label and numerous words denoting symptoms.  The Curse of Dimensionality at work?  We will use the power of an LSTM and a CNN along with word embeddings to develop a basic text classification pipeline and see how far we can go with this dataset.</p>
<p>We discuss code fragments here.  The pointer to the complete code appear at the end of this article.</p>
<h2 id="import-libraries">Import libraries</h2>
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">keras</span> <span style="color:#008000;font-weight:bold">import</span> regularizers, optimizers
<span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">keras.layers.experimental.preprocessing</span> <span style="color:#008000;font-weight:bold">import</span> TextVectorization
<span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">keras.layers</span> <span style="color:#008000;font-weight:bold">import</span> Embedding, Dense, Dropout, Input, LSTM, Conv1D, GlobalMaxPool1D,GlobalAveragePooling1D
<span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">keras.models</span> <span style="color:#008000;font-weight:bold">import</span> Sequential
<span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">keras.initializers</span> <span style="color:#008000;font-weight:bold">import</span> Constant
<span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">tensorflow</span> <span style="color:#008000;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">tf</span>
<span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">spacy</span>
<span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">en_core_web_lg</span>  <span style="color:#408080;font-style:italic"># Spacy large language model</span>
</code></pre></div><h2 id="get-your-favourite-embeddings">Get your favourite embeddings</h2>
<p>We use spacy large model embeddings as encoding for our words.</p>
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">nlp <span style="color:#666">=</span> en_core_web_lg<span style="color:#666">.</span>load()
<span style="color:#666">...</span>
</code></pre></div><h2 id="create-a-vectorizer-layer">Create a vectorizer layer</h2>
<p>The Keras vectorizer layer converts words to integers.  We have the facility to specify the cutoff frequency to get the most frequent words in the vocabulary and also a padding/truncation length per document.  This layer helps us feed text directly to the Keras model.</p>
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#666">...</span>
disease_vectorizer <span style="color:#666">=</span> TextVectorization(max_tokens<span style="color:#666">=</span><span style="color:#666">5000</span>,output_sequence_length<span style="color:#666">=</span>None)

<span style="color:#408080;font-style:italic"># We fit our vectorizer on our text and extract our corpus</span>
disease_vectorizer<span style="color:#666">.</span>adapt(X_retain<span style="color:#666">.</span>to_numpy())
vocab <span style="color:#666">=</span> disease_vectorizer<span style="color:#666">.</span>get_vocabulary()
<span style="color:#666">...</span>
</code></pre></div><h2 id="create-the-embedding-layer">Create the embedding layer</h2>
<p>The embedding layer goes before the LSTM and contains the embedding matrix that maps word integer codes to the corresponding word embedding.</p>
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#666">...</span>
<span style="color:#408080;font-style:italic"># Generating the embedding matrix</span>
ntokens <span style="color:#666">=</span> <span style="color:#008000">len</span>(vocab)
embed_dim <span style="color:#666">=</span> <span style="color:#008000">len</span>(nlp(<span style="color:#ba2121">&#39;The&#39;</span>)<span style="color:#666">.</span>vector)
embed_matrix <span style="color:#666">=</span> np<span style="color:#666">.</span>zeros((ntokens, embed_dim))
<span style="color:#008000;font-weight:bold">for</span> i, word <span style="color:#a2f;font-weight:bold">in</span> tqdm(<span style="color:#008000">enumerate</span>(vocab)):
    embed_matrix[i] <span style="color:#666">=</span> nlp(<span style="color:#008000">str</span>(word))<span style="color:#666">.</span>vector
    
<span style="color:#408080;font-style:italic"># Load the embedding matrix as the weights matrix for the embedding layer</span>
Embed_layer<span style="color:#666">=</span>Embedding(
    ntokens,
    embed_dim,
    embeddings_initializer<span style="color:#666">=</span>Constant(embed_matrix),
    trainable<span style="color:#666">=</span>False)
<span style="color:#666">...</span>
</code></pre></div><h2 id="create-the-model">Create the model</h2>
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#666">...</span>
FILTERS <span style="color:#666">=</span> <span style="color:#666">24</span>
KERNEL_SIZE <span style="color:#666">=</span> <span style="color:#666">3</span>

<span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">keras.metrics</span> <span style="color:#008000;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">kmetrics</span>
<span style="color:#408080;font-style:italic"># We fit a large model as our dataset is reasonably huge.</span>
model <span style="color:#666">=</span> Sequential()
<span style="color:#408080;font-style:italic"># The vectorizer layer</span>
model<span style="color:#666">.</span>add(Input(shape<span style="color:#666">=</span>(<span style="color:#666">1</span>,), dtype<span style="color:#666">=</span>tf<span style="color:#666">.</span>string))
model<span style="color:#666">.</span>add(disease_vectorizer)
<span style="color:#408080;font-style:italic"># Add the embedding layer</span>
model<span style="color:#666">.</span>add(Embed_layer)

model<span style="color:#666">.</span>add(LSTM(<span style="color:#666">25</span>, return_sequences<span style="color:#666">=</span>True))
model<span style="color:#666">.</span>add(Conv1D(FILTERS,
                 KERNEL_SIZE,
                 padding<span style="color:#666">=</span><span style="color:#ba2121">&#39;same&#39;</span>,
                 strides<span style="color:#666">=</span><span style="color:#666">1</span>,
                 activation<span style="color:#666">=</span><span style="color:#ba2121">&#39;tanh&#39;</span>, 
                 ))

model<span style="color:#666">.</span>add(GlobalAveragePooling1D())
<span style="color:#408080;font-style:italic">#model.add(GlobalMaxPool1D())</span>
model<span style="color:#666">.</span>add(Dropout(<span style="color:#666">0.5</span>))
model<span style="color:#666">.</span>add(Dense(<span style="color:#666">32</span>, activation<span style="color:#666">=</span><span style="color:#ba2121">&#39;tanh&#39;</span>, kernel_regularizer<span style="color:#666">=</span>regularizers<span style="color:#666">.</span>l1_l2(l1<span style="color:#666">=</span><span style="color:#666">1e-5</span>,l2<span style="color:#666">=</span><span style="color:#666">1e-4</span>)))
model<span style="color:#666">.</span>add(Dropout(<span style="color:#666">0.5</span>))
model<span style="color:#666">.</span>add(Dense(<span style="color:#666">32</span>, activation<span style="color:#666">=</span><span style="color:#ba2121">&#39;tanh&#39;</span>, kernel_regularizer<span style="color:#666">=</span>regularizers<span style="color:#666">.</span>l1_l2(l1<span style="color:#666">=</span><span style="color:#666">1e-5</span>,l2<span style="color:#666">=</span><span style="color:#666">1e-4</span>)))
model<span style="color:#666">.</span>add(Dense(<span style="color:#666">24</span>,activation<span style="color:#666">=</span><span style="color:#ba2121">&#39;softmax&#39;</span>))

<span style="color:#408080;font-style:italic"># Now add in your optimizer</span>
model<span style="color:#666">.</span>compile(optimizer<span style="color:#666">=</span><span style="color:#ba2121">&#39;adam&#39;</span>, loss<span style="color:#666">=</span><span style="color:#ba2121">&#39;categorical_crossentropy&#39;</span>,metrics<span style="color:#666">=</span>[<span style="color:#ba2121">&#39;accuracy&#39;</span>,kmetrics<span style="color:#666">.</span>Precision(),
                               kmetrics<span style="color:#666">.</span>Recall()])

<span style="color:#408080;font-style:italic"># Print the summary of the model</span>
<span style="color:#008000;font-weight:bold">print</span>(model<span style="color:#666">.</span>summary())
<span style="color:#666">...</span>
</code></pre></div><p>The model has dropout layers to prevent overfitting.  Also, the <code>GlobalAvgPool1D</code> pooling layer helps generate a document embedding of sorts.  Remember that labels have to be one-hot encoded for the output activation to be softmax.</p>
<h2 id="model-training">Model training</h2>
<p>We track our model training by gathering model training history for accuracy, precision and recall after each epoch.  The post-training plots of these metrics shows us when to stop training to prevent overfitting.</p>
<div class="highlight"><pre style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">n_epochs <span style="color:#666">=</span> <span style="color:#666">200</span>
batch_size <span style="color:#666">=</span> <span style="color:#666">20</span>
<span style="color:#408080;font-style:italic"># Now, fit the model</span>
history <span style="color:#666">=</span> model<span style="color:#666">.</span>fit(x<span style="color:#666">=</span>X_retain, y<span style="color:#666">=</span>y_retain,
                    batch_size <span style="color:#666">=</span> batch_size,
                    epochs <span style="color:#666">=</span> n_epochs,
                    validation_split<span style="color:#666">=.</span><span style="color:#666">3</span>
                   )
</code></pre></div><p>The output fragment:</p>
<pre><code>Epoch 1/200
26/26 [==============================] - 5s 59ms/step - loss: 3.1886 - accuracy: 0.0676 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 3.1381 - val_accuracy: 0.0968 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
Epoch 2/200
26/26 [==============================] - 1s 23ms/step - loss: 3.0858 - accuracy: 0.0974 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 3.0663 - val_accuracy: 0.0968 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
Epoch 3/200
26/26 [==============================] - 1s 26ms/step - loss: 2.9604 - accuracy: 0.1750 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.9370 - val_accuracy: 0.1659 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
...

Epoch 198/200
26/26 [==============================] - 1s 26ms/step - loss: 0.2708 - accuracy: 0.9165 - precision: 0.9357 - recall: 0.8966 - val_loss: 1.2114 - val_accuracy: 0.7235 - val_precision: 0.7549 - val_recall: 0.7097
Epoch 199/200
26/26 [==============================] - 1s 24ms/step - loss: 0.3016 - accuracy: 0.9046 - precision: 0.9382 - recall: 0.8748 - val_loss: 1.2121 - val_accuracy: 0.7143 - val_precision: 0.7476 - val_recall: 0.7097
Epoch 200/200
26/26 [==============================] - 1s 25ms/step - loss: 0.3549 - accuracy: 0.8887 - precision: 0.9053 - recall: 0.8748 - val_loss: 1.1697 - val_accuracy: 0.7097 - val_precision: 0.7704 - val_recall: 0.6959
</code></pre><h2 id="classification-report">Classification report</h2>
<pre><code>                                 precision    recall  f1-score   support

                           Acne       0.95      0.95      0.95        20
                      Arthritis       1.00      0.95      0.97        20
               Bronchial Asthma       0.65      0.65      0.65        20
           Cervical spondylosis       0.65      1.00      0.78        20
                    Chicken pox       0.40      0.30      0.34        20
                    Common Cold       0.71      0.85      0.77        20
                         Dengue       0.58      0.55      0.56        20
          Dimorphic Hemorrhoids       0.72      0.90      0.80        20
               Fungal infection       0.86      0.95      0.90        20
                   Hypertension       0.82      0.90      0.86        20
                       Impetigo       0.95      0.95      0.95        20
                       Jaundice       0.56      1.00      0.71        20
                        Malaria       0.90      0.95      0.93        20
                       Migraine       1.00      0.75      0.86        20
                      Pneumonia       0.80      0.40      0.53        20
                      Psoriasis       0.72      0.65      0.68        20
                        Typhoid       0.60      0.45      0.51        20
                 Varicose Veins       0.73      0.95      0.83        20
                        allergy       0.69      0.55      0.61        20
                       diabetes       0.60      0.45      0.51        20
                  drug reaction       0.50      0.35      0.41        20
gastroesophageal reflux disease       0.67      0.80      0.73        20
           peptic ulcer disease       0.58      0.55      0.56        20
        urinary tract infection       0.71      0.50      0.59        20

                       accuracy                           0.72       480
                      macro avg       0.72      0.72      0.71       480
                   weighted avg       0.72      0.72      0.71       480


</code></pre><h2 id="takeaway">Takeaway</h2>
<p>The classification report shows us different precision and recall values for each class label.  This is understandable because many diseases have common symptoms.</p>
<p>For the complete code in context, refer to my <a href="https://www.kaggle.com/code/atrijtalgery/lstm-cnn-docembedding-75-on-holdout">Kaggle notebook</a>.</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/nlp/" rel="tag">nlp</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/lstm/" rel="tag">lstm</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/cnn/" rel="tag">cnn</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/classification/" rel="tag">classification</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/regressor-as-classifier/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Regressor as Classifier</p>
		</a>
	</div>
</nav>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
<div class="footer__links">
	<a class="footer__link" href="/about/">About</a>
</div>
		<div class="footer__copyright">
			&copy; 2024 Atrij Talgery.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>